{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Korean_preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOpdu8Q+jrz/QXLjLxSNriu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"zsFOY6a6Tpr7"},"source":["# corpus 얻기 위한 부분 -> 선택적인 코드\n","!pip install newspaper3k\n","import newspaper\n","newspaper.languages()\n","news_url = \"https://kimziont.github.io/nlp_ustage/week3_special_lecture_1/\"\n","article = newspaper.Article(news_url, language='ko')\n","article.download()\n","article.parse()\n","context = article.text.split('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVeieNl4E2qM"},"source":["# 문장 단위 tokenization\n","def sentence_tokenization(texts):\n","    flag = True\n","    while flag:\n","        try:\n","            import kss\n","            flag = False\n","        except ModuleNotFoundError:\n","            answer = input(\"You need 'kss' module do you want to install it? [yes/no]\")\n","            if answer == \"yes\":\n","                ! pip install kss\n","            elif answer == \"no\":\n","                print(\"'sentence_tokenization' is terminated\")\n","                return texts\n","            else:\n","                answer = input(\"Wrong answer, Do you want to install 'kss' [yes/no]\")\n","\n","    sents = []\n","    for sent in texts:\n","        sent = sent.strip()\n","        if sent:\n","            splited_sent = kss.split_sentences(sent)\n","            sents.extend(splited_sent)\n","    return sents"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FqvZiRtMCGK"},"source":["# html 태그 제거\n","def remove_html(texts):\n","    import re\n","    \"\"\"\n","    HTML 태그를 제거합니다.\n","    ``<p>안녕하세요 ㅎㅎ </p>`` -> ``안녕하세요 ㅎㅎ ``\n","    \"\"\"\n","    \n","    preprcessed_text = []\n","    for text in texts:\n","        text = re.sub(r\"<[^>]+>\\s+(?=<)|<[^>]+>\", \"\", text).strip()\n","        if text:\n","            preprcessed_text.append(text)\n","    return preprcessed_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T8Qp_YKKFYeq"},"source":["# 두 개 이상의 연속된 공백을 하나로 치환\n","def remove_repeated_spacing(corpus):\n","    import re\n","    \"\"\"\n","    두 개 이상의 연속된 공백을 하나로 치환합니다.\n","    ``오늘은    날씨가   좋다.`` -> ``오늘은 날씨가 좋다.``\n","    \"\"\"\n","\n","    preprocessed_text = []\n","    for text in corpus:\n","        text = re.sub(r\"\\s+\", \" \", text).strip()\n","        if text:\n","            preprocessed_text.append(text)\n","    return preprocessed_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbg850CaIYM3"},"source":["# 반복되는 문자 num_repeats개 만큼만 사용\n","def remove_repeat_char(texts):\n","    flag = True\n","    while flag:\n","        try:\n","            from soynlp.normalizer import repeat_normalize\n","            flag = False\n","        except ModuleNotFoundError:\n","            answer = input(\"You need 'soynlp' module do you want to install it? [yes/no]\")\n","            if answer == \"yes\":\n","                ! pip install soynlp\n","            elif answer == \"no\":\n","                print(\"'remove_repeat_char' is terminated\")\n","                return texts\n","            else:\n","                print(\"Wrong answer\")\n","\n","    preprocessed_text = []\n","    for text in texts:\n","        text = repeat_normalize(text, num_repeats=3).strip()\n","        if text:\n","            preprocessed_text.append(text)\n","    return preprocessed_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d9JPlKngMagD"},"source":["class PreprocesKorean:\n","    def __init__(self, texts):\n","        self.texts = texts\n","        self.preprocess_dict = {0: \"sentence_tokenization\", 1: \"remove_html\", 2: \"remove_repeated_spacing\",\n","                                3: \"remove_repeat_char\"}\n","        print(\"Choose numbers to preprocessing what you want. you can check through 'preproces_dict' attribute\")\n","        print(f\"list of preprocessing texts: {self.preprocess_dict}\\n\")\n","    \n","    def __call__(self, *nums):\n","        preprocessed_texts = self.texts\n","        for num in nums:\n","            print(f\"{self.preprocess_dict[num]} is in process!\")\n","            preprocessed_texts = eval(f\"{self.preprocess_dict[num]}(preprocessed_texts)\")\n","        print(\"preprocessing is completed!\\n\")\n","        return preprocessed_texts"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gT7sSBl-QIBe"},"source":["preprocessing_kor = PreprocesKorean(context)\n","\n","preprocessed_texts = preprocessing_kor(0, 1, 2, 3)\n","\n","for idx, text in enumerate(preprocessed_texts):\n","    print(idx, text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vd-wQlZZQ89"},"source":[""],"execution_count":null,"outputs":[]}]}